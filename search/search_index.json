{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CloudDocs","text":"<p>Welcome to my cloud and DevOps project website, where all my labs and projects come together under one roof.</p> <p>Here, you'll find a collection of hands-on experiences, challenges, and triumphs from my journey in the realm of cloud computing and DevOps. Whether you're here to explore, learn, or get inspired, this is your gateway to a world of innovation, automation, and continuous learning.</p> <p>Check out my labs for hands-on learning experiences and practical insights.</p>"},{"location":"ASG/","title":"Configuring a Highly Available and Secure Application on AWS with Terraform","text":"<p>Learn to create a robust AWS infrastructure using Terraform that includes an Auto Scaling Group (ASG), Application Load Balancer (ALB), security groups, launch templates, and a Web Application Firewall (WAF) within a custom VPC, and DNS configuration with Route 53.</p>"},{"location":"ASG/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have the following:</p> <ul> <li>Terraform installed</li> <li>An AWS account with appropriate permissions</li> <li>AWS CLI with configured credentials</li> <li>A basic understanding of AWS and Terraform</li> <li>Code editor (VS Code)</li> </ul>"},{"location":"ASG/#step-1-aws-provider-setup-terraform-block","title":"Step 1: AWS Provider Setup &amp; terraform block","text":"<p>Define your AWS provider with the desired region and specify the required providers for Terraform.</p> <pre><code>provider \"aws\" {\n  region = \"us-east-1\"\n}\n\nterraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 3.0\"\n    }\n  }\n}\n</code></pre>"},{"location":"ASG/#step-2-create-the-vpc","title":"Step 2: Create the VPC","text":"<p>Define your Virtual Private Cloud (VPC) with a CIDR block and tags.</p> <pre><code>resource \"aws_vpc\" \"app1\" {\n  cidr_block = \"10.74.0.0/16\"\n\n  tags = {\n    Name = \"app1\"\n    Service = \"application1\"\n    Owner = \"Chewbacca\"\n    Planet = \"Mustafar\"\n  }\n}\n</code></pre>"},{"location":"ASG/#step-3-set-up-subnets","title":"Step 3: Set Up Subnets","text":"<p>Create subnets within your VPC. Subnets can be public or private and are typically distributed across multiple availability zones for high availability. </p> <pre><code>#These are   for  public\n\nresource \"aws_subnet\" \"public-us-east-1a\" {\n  vpc_id                  = aws_vpc.app1.id\n  cidr_block              = \"10.74.1.0/24\"\n  availability_zone       = \"us-east-1\"\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name = \"public-us-east-1a\"\n    Service = \"application1\"\n    Owner = \"Chewbacca\"\n    Planet = \"Musafar\"\n  }\n}\n\nresource \"aws_subnet\" \"public-us-east-1d\" {\n  vpc_id                  = aws_vpc.app1.id\n  cidr_block              = \"10.74.4.0/24\"\n  availability_zone       = \"us-east-1d\"\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name = \"public-us-east-1d\"\n    Service = \"application1\"\n    Owner = \"Chewbacca\"\n    Planet = \"Musafar\"\n  }\n}\n\nresource \"aws_subnet\" \"public-us-east-1c\" {\n  vpc_id                  = aws_vpc.app1.id\n  cidr_block              = \"10.74.3.0/24\"\n  availability_zone       = \"us-east-1c\"\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name = \"public-us-east-1c\"\n    Service = \"application1\"\n    Owner = \"Chewbacca\"\n    Planet = \"Musafar\"\n  }\n}\n\n\n\n#these are for private\nresource \"aws_subnet\" \"private-us-east-1a\" {\n  vpc_id            = aws_vpc.app1.id\n  cidr_block        = \"10.74.11.0/24\"\n  availability_zone = \"us-east-1\"\n\n  tags = {\n    Name = \"private-us-east-1a\"\n    Service = \"application1\"\n    Owner = \"Chewbacca\"\n    Planet = \"Musafar\"\n  }\n}\n\nresource \"aws_subnet\" \"private-us-east-1d\" {\n  vpc_id            = aws_vpc.app1.id\n  cidr_block        = \"10.74.14.0/24\"\n  availability_zone = \"us-east-1d\"\n\n  tags = {\n    Name = \"private-us-east-1d\"\n    Service = \"application1\"\n    Owner = \"Chewbacca\"\n    Planet = \"Musafar\"\n  }\n}\n\nresource \"aws_subnet\" \"private-us-east-1c\" {\n  vpc_id            = aws_vpc.app1.id\n  cidr_block        = \"10.74.13.0/24\"\n  availability_zone = \"us-east-1c\"\n\n  tags = {\n    Name = \"private-us-east-1d\"\n    Service = \"application1\"\n    Owner = \"Chewbacca\"\n    Planet = \"Musafar\"\n  }\n}\n</code></pre>"},{"location":"ASG/#step-4-internet-gateway","title":"Step 4: Internet Gateway","text":"<p>Establish an Internet Gateway (IG) to allow communication between your VPC and the internet.</p> <pre><code>resource \"aws_internet_gateway\" \"igw\" {\n  vpc_id = aws_vpc.app1.id\n\n  tags = {\n    Name    = \"app1_IG\"\n    Service = \"application1\"\n    Owner   = \"Luke\"\n    Planet  = \"Musafar\"\n  }\n}\n</code></pre>"},{"location":"ASG/#step-5-nat-gateway","title":"Step 5: NAT Gateway","text":"<p>Implement a NAT Gateway to enable instances in a private subnet to connect to the internet or other AWS services but prevent the internet from initiating connections with the instances.</p> <pre><code>resource \"aws_eip\" \"nat\" {\n  vpc = true\n\n  tags = {\n    Name = \"nat\"\n  }\n}\n\nresource \"aws_nat_gateway\" \"nat\" {\n  allocation_id = aws_eip.nat.id\n  subnet_id     = aws_subnet.public-ap-northeast-2a.id\n\n  tags = {\n    Name = \"nat\"\n  }\n\n  depends_on = [aws_internet_gateway.igw]\n}\n</code></pre>"},{"location":"ASG/#step-6-route-tables","title":"Step 6: Route Tables","text":"<p>Configure route tables to define rules for traffic routing within your VPC.</p> <pre><code>resource \"aws_route_table\" \"private\" {\n  vpc_id = aws_vpc.app1.id\n\n  route = [\n    {\n      cidr_block                 = \"0.0.0.0/0\"\n      nat_gateway_id             = aws_nat_gateway.nat.id\n      carrier_gateway_id         = \"\"\n      destination_prefix_list_id = \"\"\n      egress_only_gateway_id     = \"\"\n      gateway_id                 = \"\"\n      instance_id                = \"\"\n      ipv6_cidr_block            = \"\"\n      local_gateway_id           = \"\"\n      network_interface_id       = \"\"\n      transit_gateway_id         = \"\"\n      vpc_endpoint_id            = \"\"\n      vpc_peering_connection_id  = \"\"\n    },\n  ]\n\n  tags = {\n    Name = \"private\"\n  }\n}\n\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.app1.id\n\n  route = [\n    {\n      cidr_block                 = \"0.0.0.0/0\"\n      gateway_id                 = aws_internet_gateway.igw.id\n      nat_gateway_id             = \"\"\n      carrier_gateway_id         = \"\"\n      destination_prefix_list_id = \"\"\n      egress_only_gateway_id     = \"\"\n      instance_id                = \"\"\n      ipv6_cidr_block            = \"\"\n      local_gateway_id           = \"\"\n      network_interface_id       = \"\"\n      transit_gateway_id         = \"\"\n      vpc_endpoint_id            = \"\"\n      vpc_peering_connection_id  = \"\"\n    },\n  ]\n\n  tags = {\n    Name = \"public\"\n  }\n}\n\nresource \"aws_route_table_association\" \"private-us-east-1a\" {\n  subnet_id      = aws_subnet.private-us-east-1a.id\n  route_table_id = aws_route_table.private.id\n}\n\nresource \"aws_route_table_association\" \"private-us-east-1d\" {\n  subnet_id      = aws_subnet.private-us-east-1d.id\n  route_table_id = aws_route_table.private.id\n}\n\nresource \"aws_route_table_association\" \"public-us-east-1a\" {\n  subnet_id      = aws_subnet.public-us-east-1a.id\n  route_table_id = aws_route_table.public.id\n}\n\nresource \"aws_route_table_association\" \"public-us-east-1d\" {\n  subnet_id      = aws_subnet.public-us-east-1d.id\n  route_table_id = aws_route_table.public.id\n}\n\nresource \"aws_route_table_association\" \"public-us-east-1c\" {\n  subnet_id      = aws_subnet.public-us-east-1c.id\n  route_table_id = aws_route_table.private.id\n}\n\nresource \"aws_route_table_association\" \"private-us-east-1c\" {\n  subnet_id      = aws_subnet.private-us-east-1c.id\n  route_table_id = aws_route_table.private.id\n}\n</code></pre>"},{"location":"ASG/#step-7-security-groups","title":"Step 7: Security Groups","text":"<p>Define security groups to control the traffic to and from your instances. You'll want to allow web traffic and restrict all unnecessary access.</p> <pre><code>resource \"aws_security_group\" \"app1-sg01-servers\" {\n  name        = \"app1-sg01-servers\"\n  description = \"app1-sg01-servers\"\n  vpc_id      = aws_vpc.app1.id\n\n  ingress {\n    description = \"MyHomePage\"\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n  ingress {\n    description = \"SecureMyHomePage\"\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n\n  ingress {\n    description = \"SSH\"\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  ingress {\n    description = \"MyEvilBox\"\n    from_port   = 3389\n    to_port     = 3389\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name    = \"app1-sg01-servers\"\n    Service = \"application1\"\n    Owner   = \"Luke\"\n    Planet  = \"Musafar\"\n  }\n\n}\n\n\n\n\n\nresource \"aws_security_group\" \"app1-sg02-LB01\" {\n  name        = \"app1-sg02-LB01\"\n  description = \"app1-sg02-LB01\"\n  vpc_id      = aws_vpc.app1.id\n\n  ingress {\n    description = \"MyHomePage\"\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  ingress {\n    description = \"SecureMyHomePage\"\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name    = \"app1-sg02-LB01\"\n    Service = \"application1\"\n    Owner   = \"Luke\"\n    Planet  = \"Musafar\"\n  }\n\n}\n</code></pre>"},{"location":"ASG/#step-8-launch-template","title":"Step 8: Launch Template","text":"<p>Create a launch template for your EC2 instances. This will define the AMI, instance type, and the security group among other settings. Also when adding user data you have to encode it using base64. To do that use the following command to encode it and to output it to a text file. replace path to file with the relative path to your user data file. </p> <pre><code>base64 /path/to/file &gt; output.txt\n</code></pre> <pre><code>resource \"aws_launch_template\" \"app1_LT\" {\n  name_prefix   = \"app1_LT\"\n  image_id      = \"ami-0e01e66dacaf1454d\"  \n  instance_type = \"t2.micro\"\n\n  key_name = \"MyLinuxBox\"\n\n  vpc_security_group_ids = [aws_security_group.app1-sg01-servers.id]\n\n  user_data = \"${file(\"output.txt\")}\"\n\n  tag_specifications {\n    resource_type = \"instance\"\n    tags = {\n      Name    = \"app1_LT\"\n      Service = \"application1\"\n      Owner   = \"Chewbacca\"\n      Planet  = \"Mustafar\"\n    }\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n</code></pre>"},{"location":"ASG/#step-9-target-group","title":"Step 9: Target Group","text":"<p>Set up a target group for your load balancer to direct traffic to. The target group defines health check settings and which instances should receive traffic.</p> <pre><code>resource \"aws_lb_target_group\" \"app1_tg\" {\n  name     = \"app1-target-group\"\n  port     = 80\n  protocol = \"HTTP\"\n  vpc_id   = aws_vpc.app1.id\n  target_type = \"instance\"\n\n  health_check {\n    enabled             = true\n    interval            = 30\n    path                = \"/\"\n    protocol            = \"HTTP\"\n    healthy_threshold   = 10\n    unhealthy_threshold = 2\n    timeout             = 5\n    matcher             = \"200\"\n  }\n\n  tags = {\n    Name    = \"App1TargetGroup\"\n    Service = \"App1\"\n    Owner   = \"User\"\n    Project = \"Web Service\"\n  }\n}\n</code></pre>"},{"location":"ASG/#step-10-load-balancer","title":"Step 10: Load Balancer","text":"<p>Deploy an Application Load Balancer (ALB) to distribute incoming application traffic across multiple targets, such as EC2 instances.</p> <pre><code>resource \"aws_lb\" \"app1_alb\" {\n  name               = \"app1-load-balancer\"\n  internal           = false\n  load_balancer_type = \"application\"\n  security_groups    = [aws_security_group.app1-sg02-LB01.id]\n  subnets            = [\n    aws_subnet.public-ap-northeast-2a.id,\n    aws_subnet.public-ap-northeast-2c.id,\n    aws_subnet.public-ap-northeast-2d.id,\n  ]\n  enable_deletion_protection = false\n\n  tags = {\n    Name    = \"App1LoadBalancer\"\n    Service = \"App1\"\n    Owner   = \"User\"\n    Project = \"Web Service\"\n  }\n}\n\nresource \"aws_lb_listener\" \"http\" {\n  load_balancer_arn = aws_lb.app1_alb.arn\n  port              = 80\n  protocol          = \"HTTP\"\n\n  # default_action {\n  #   type             = \"forward\"\n  #   target_group_arn = aws_lb_target_group.app1_tg.arn\n  # }\n\n    default_action {\n    type = \"redirect\"\n\n    redirect {\n      port        = \"443\"\n      protocol    = \"HTTPS\"\n      status_code = \"HTTP_301\"\n    }\n  }\n}\n</code></pre>"},{"location":"ASG/#step-11-auto-scaling-group","title":"Step 11: Auto Scaling Group","text":"<p>Create an Auto Scaling Group (ASG) that uses the launch template and target group to maintain application availability and scale your EC2 instances automatically.</p> <pre><code>resource \"aws_autoscaling_group\" \"app1_asg\" {\n  name_prefix           = \"app1-auto-scaling-group-\"\n  min_size              = 3\n  max_size              = 15\n  desired_capacity      = 6\n  vpc_zone_identifier   = [\n    aws_subnet.private-us-east-1a.id,\n    aws_subnet.private-us-east-1c.id,\n    aws_subnet.private-us-east-1d.id,\n  ]\n  health_check_type          = \"ELB\"\n  health_check_grace_period  = 300\n  force_delete               = true\n  target_group_arns          = [aws_lb_target_group.app1_tg.arn]\n\n  launch_template {\n    id      = aws_launch_template.app1_LT.id\n    version = \"$Latest\"\n  }\n\n  enabled_metrics = [\"GroupMinSize\", \"GroupMaxSize\", \"GroupDesiredCapacity\", \"GroupInServiceInstances\", \"GroupTotalInstances\"]\n\n  # Instance protection for launching\n  initial_lifecycle_hook {\n    name                  = \"instance-protection-launch\"\n    lifecycle_transition  = \"autoscaling:EC2_INSTANCE_LAUNCHING\"\n    default_result        = \"CONTINUE\"\n    heartbeat_timeout     = 60\n    notification_metadata = \"{\\\"key\\\":\\\"value\\\"}\"\n  }\n\n  # Instance protection for terminating\n  initial_lifecycle_hook {\n    name                  = \"scale-in-protection\"\n    lifecycle_transition  = \"autoscaling:EC2_INSTANCE_TERMINATING\"\n    default_result        = \"CONTINUE\"\n    heartbeat_timeout     = 300\n  }\n\n  tag {\n    key                 = \"Name\"\n    value               = \"app1-instance\"\n    propagate_at_launch = true\n  }\n\n  tag {\n    key                 = \"Environment\"\n    value               = \"Production\"\n    propagate_at_launch = true\n  }\n}\n\n\n# Auto Scaling Policy\nresource \"aws_autoscaling_policy\" \"app1_scaling_policy\" {\n  name                   = \"app1-cpu-target\"\n  autoscaling_group_name = aws_autoscaling_group.app1_asg.name\n\n  policy_type = \"TargetTrackingScaling\"\n  estimated_instance_warmup = 120\n\n  target_tracking_configuration {\n    predefined_metric_specification {\n      predefined_metric_type = \"ASGAverageCPUUtilization\"\n    }\n    target_value = 75.0\n  }\n}\n\n# Enabling instance scale-in protection\nresource \"aws_autoscaling_attachment\" \"app1_asg_attachment\" {\n  autoscaling_group_name = aws_autoscaling_group.app1_asg.name\n  alb_target_group_arn   = aws_lb_target_group.app1_tg.arn\n}\n</code></pre>"},{"location":"ASG/#step-12-route-53","title":"Step 12: Route 53","text":"<p>Utilize AWS Route 53 to create a DNS record that points to your ALB, providing a friendly domain name for your users.</p> <pre><code>data \"aws_route53_zone\" \"public\" {\n  name         = \"abudevops.com\"\n  private_zone = false\n}\n\nresource \"aws_acm_certificate\" \"api\" {\n  domain_name       = \"abudevops.com\"\n  validation_method = \"DNS\"\n}\n\nresource \"aws_route53_record\" \"api_validation\" {\n  for_each = {\n    for dvo in aws_acm_certificate.api.domain_validation_options : dvo.domain_name =&gt; {\n      name   = dvo.resource_record_name\n      record = dvo.resource_record_value\n      type   = dvo.resource_record_type\n    }\n  }\n\n  allow_overwrite = true\n  name            = each.value.name\n  records         = [each.value.record]\n  ttl             = 60\n  type            = each.value.type\n  zone_id         = data.aws_route53_zone.public.zone_id\n}\n\nresource \"aws_acm_certificate_validation\" \"api\" {\n  certificate_arn         = aws_acm_certificate.api.arn\n  validation_record_fqdns = [for record in aws_route53_record.api_validation : record.fqdn]\n}\n\nresource \"aws_route53_record\" \"api\" {\n  name    = aws_acm_certificate.api.domain_name\n  type    = \"A\"\n  zone_id = data.aws_route53_zone.public.zone_id\n\n  alias {\n    name                   = aws_lb.app1_alb.dns_name\n    zone_id                = aws_lb.app1_alb.zone_id\n    evaluate_target_health = false\n  }\n}\n\nresource \"aws_lb_listener\" \"my_app_eg2_tls\" {\n  load_balancer_arn = aws_lb.app1_alb.arn\n  port              = \"443\"\n  protocol          = \"HTTPS\"\n  certificate_arn   = aws_acm_certificate.api.arn\n  ssl_policy        = \"ELBSecurityPolicy-2016-08\"\n\n  default_action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.app1_tg.arn\n  }\n\n  depends_on = [aws_acm_certificate_validation.api]\n}\n\noutput \"custom_domain\" {\n  value = \"https://${aws_acm_certificate.api.domain_name}\"\n}\n</code></pre>"},{"location":"ASG/#step-13-web-application-firewall-waf","title":"Step 13: Web Application Firewall (WAF)","text":"<p>Lastly, enhance security by implementing a Web Application Firewall (WAF). This will protect your web application from common web exploits.</p> <pre><code>resource \"aws_wafv2_web_acl\" \"WafWebAcl\" {\n  name  = \"wafv2-web-acl\"\n  scope = \"REGIONAL\"\n\n  default_action {\n    allow {}\n  }\n\n  visibility_config {\n    cloudwatch_metrics_enabled = true\n    metric_name                = \"WAF_Common_Protections\"\n    sampled_requests_enabled   = true\n  }\n\n  rule {\n    name     = \"AWS-AWSManagedRulesCommonRuleSet\"\n    priority = 0\n    override_action {\n      none {}\n    }\n    statement {\n      managed_rule_group_statement {\n        name        = \"AWSManagedRulesCommonRuleSet\"\n        vendor_name = \"AWS\"\n        # Excluded rules can be specified here if needed\n        # excluded_rules {\n        #   name = \"SizeRestrictions_BODY\"\n        # }\n        # excluded_rules {\n        #   name = \"NoUserAgent_HEADER\"\n        # }\n      }\n    }\n    visibility_config {\n      cloudwatch_metrics_enabled = true\n      metric_name                = \"AWS-AWSManagedRulesCommonRuleSet\"\n      sampled_requests_enabled   = true\n    }\n  }\n\n  # ... other rules here ...\n\n  # Example for additional rules (make sure to increment the priority for each rule)\n  rule {\n    name     = \"AWS-AWSManagedRulesLinuxRuleSet\"\n    priority = 1\n    override_action {\n      none {}\n    }\n    statement {\n      managed_rule_group_statement {\n        name        = \"AWSManagedRulesLinuxRuleSet\"\n        vendor_name = \"AWS\"\n      }\n    }\n    visibility_config {\n      cloudwatch_metrics_enabled = true\n      metric_name                = \"AWS-AWSManagedRulesLinuxRuleSet\"\n      sampled_requests_enabled   = true\n    }\n  }\n\n  rule {\n    name     = \"AWS-AWSManagedRulesWindowsRuleSet\"\n    priority = 10\n    override_action {\n      none {}\n    }\n    statement {\n      managed_rule_group_statement {\n        name        = \"AWS-AWSManagedRulesWindowsRuleSet\"\n        vendor_name = \"AWS\"\n      }\n    }\n    visibility_config {\n      cloudwatch_metrics_enabled = true\n      metric_name                = \"AWS-AWSManagedRulesWindowsRuleSet\"\n      sampled_requests_enabled   = true\n    }\n  }\n\n  rule {\n    name     = \"AWS-AWSManagedRulesKnownBadInputsRuleSet\"\n    priority = 20\n    override_action {\n      none {}\n    }\n    statement {\n      managed_rule_group_statement {\n        name        = \"AWS-AWSManagedRulesKnownBadInputsRuleSet\"\n        vendor_name = \"AWS\"\n      }\n    }\n    visibility_config {\n      cloudwatch_metrics_enabled = true\n      metric_name                = \"AWS-AWSManagedRulesKnownBadInputsRuleSet\"\n      sampled_requests_enabled   = true\n    }\n  }  \n\n  # Continue to define other rules as needed, incrementing the priority each time\n\n  # Don't forget to close the resource block with a closing brace.\n}\n\nresource \"aws_cloudwatch_log_group\" \"WafWebAclLoggroup\" {\n  name              = \"aws-waf-logs-wafv2-web-acl\"\n  retention_in_days = 30\n}\n\nresource \"aws_wafv2_web_acl_logging_configuration\" \"WafWebAclLogging\" {\n  log_destination_configs = [aws_cloudwatch_log_group.WafWebAclLoggroup.arn]\n  resource_arn            = aws_wafv2_web_acl.WafWebAcl.arn\n}\n\nresource \"aws_wafv2_web_acl_association\" \"WafWebAclAssociation\" {\n  resource_arn = aws_lb.app1_alb.arn  # Ensure that this resource ARN is defined elsewhere in your Terraform\n  web_acl_arn  = aws_wafv2_web_acl.WafWebAcl.arn\n}\n</code></pre> How to run Terraform <p>To run and destroy terraform, use the following commands:</p> <ol> <li> <p>terraform init</p> </li> <li> <p>terraform plan</p> </li> <li> <p>terraform apply</p> </li> <li> <p>terraform destroy</p> </li> </ol> <p></p>"},{"location":"ASG/#conclusion","title":"Conclusion","text":"<p>As we conclude this tutorial, you now have the knowledge to create a highly scalable and secure website on AWS using Terraform. You've learned how to set up the necessary infrastructure components step by step, from provisioning a VPC to deploying an Auto Scaling Group and securing your environment with WAF and Route 53.</p> <p></p>"},{"location":"AWS/","title":"AWS","text":""},{"location":"AWS/#getting-started-with-aws-labs","title":"Getting Started with AWS Labs","text":"<p>Welcome to our AWS Labs! This guide will help you quickly get started with hands-on lab exercises in Amazon Web Services (AWS).</p>"},{"location":"AWS/#prerequisites","title":"Prerequisites","text":"<p>Before diving into the labs, ensure you have the following in place:</p> <ul> <li> <p>AWS Account: You'll need an AWS account. If you don't have one, sign up at AWS Sign-Up.</p> </li> <li> <p>AWS CLI (Command Line Interface): Install the AWS CLI following AWS CLI Installation Guide.</p> </li> <li> <p>Access Key &amp; Secret Access Key: Create an AWS IAM user and generate access keys. Details in IAM User Guide.</p> </li> </ul>"},{"location":"AWS/#lab-access","title":"Lab Access","text":"<ol> <li> <p>Lab Directory: Browse our lab directory to select a lab you'd like to work on.</p> </li> <li> <p>Instructions: Open the lab instructions for step-by-step guidance.</p> </li> <li> <p>Access AWS Console: Log in to your AWS account and access the AWS Management Console.</p> </li> <li> <p>Launch Lab: Follow the lab instructions to create resources, configure services, and complete the tasks.</p> </li> </ol>"},{"location":"AWS/#lab-cleanup","title":"Lab Cleanup","text":"<ul> <li>Make sure to clean up resources after completing a lab. Follow the provided instructions to avoid unnecessary costs.</li> </ul>"},{"location":"AWS/#feedback","title":"Feedback","text":"<p>We value your feedback! If you encounter issues, have questions, or want to share your insights, please contact us at abubakrm99@gmail.com.</p> <p>Let us start exploring the world of AWS through hands-on labs! Happy learning!</p>"},{"location":"AZURE/","title":"Azure","text":""},{"location":"AZURE/#getting-started-with-azure-labs","title":"Getting Started with Azure Labs","text":"<p>Welcome to our Azure Labs! This guide will help you quickly get started with hands-on lab exercises in Microsoft Azure.</p>"},{"location":"AZURE/#prerequisites","title":"Prerequisites","text":"<p>Before diving into the labs, ensure you have the following in place:</p> <ul> <li> <p>Azure Account: You'll need an Azure account. If you don't have one, sign up at Azure Sign-Up.</p> </li> <li> <p>Azure CLI (Command Line Interface): Install the Azure CLI following Azure CLI Installation Guide.</p> </li> <li> <p>Azure Subscription: Create an Azure subscription if you haven't already.</p> </li> </ul>"},{"location":"AZURE/#lab-access","title":"Lab Access","text":"<ol> <li> <p>Lab Directory: Browse our lab directory to select a lab you'd like to work on.</p> </li> <li> <p>Instructions: Open the lab instructions for step-by-step guidance.</p> </li> <li> <p>Access Azure Portal: Log in to your Azure account and access the Azure Portal.</p> </li> <li> <p>Launch Lab: Follow the lab instructions to create resources, configure services, and complete the tasks.</p> </li> </ol>"},{"location":"AZURE/#lab-cleanup","title":"Lab Cleanup","text":"<ul> <li>Make sure to clean up resources after completing a lab. Follow the provided instructions to avoid unnecessary costs.</li> </ul>"},{"location":"AZURE/#feedback","title":"Feedback","text":"<p>We value your feedback! If you encounter issues, have questions, or want to share your insights, please contact us at abubakrm99@gmail.com.</p> <p>Let's start exploring the world of Azure through hands-on labs! Happy learning!</p>"},{"location":"DevOps/","title":"DevOps Dynamo Project","text":"<p>Welcome to the DevOps Dynamo Project Overview! In this document, I will provide a summary of a comprehensive DevOps project I have completed. This project encompasses various tools and practices to enhance the software development, deployment, and monitoring processes. If you would like to see the github repository. It is located here: https://github.com/AMohamed0/DevopsProject</p>"},{"location":"DevOps/#project-scope","title":"Project Scope","text":"<p>The primary objective of this project was to establish a robust DevOps pipeline while automating infrastructure provisioning and optimizing development workflows. Below, I will outline the key components and highlights of this project.</p>"},{"location":"DevOps/#infrastructure-and-environment","title":"Infrastructure and Environment","text":"<ul> <li> <p>Terraform for Infrastructure: Leveraged Terraform to automate the setup of cloud resources, networks, and security configurations.</p> </li> <li> <p>Jenkins Controller: Created a Jenkins controller instance to centralize CI/CD pipelines management.</p> </li> <li> <p>Build Node: Provisioned a dedicated build node to build and test application code.</p> </li> <li> <p>Ansible for Configuration: Utilized Ansible for automated configuration management tasks across the infrastructure.</p> </li> </ul> <p> </p>"},{"location":"DevOps/#cicd-pipeline-automation","title":"CI/CD Pipeline Automation","text":"<ul> <li> <p>Jenkins and Ansible Integration: Configured Jenkins controller and build node using Ansible playbooks to ensure consistent environments.</p> </li> <li> <p>Jenkins Pipeline Setup: Defined Jenkins pipeline jobs for automating the build, test, and deployment processes.</p> </li> <li> <p>Jenkinsfile Creation: Crafted Jenkinsfiles from scratch to define customized pipeline stages.</p> </li> <li> <p>Multibranch Pipeline: Implemented a multibranch pipeline for continuous integration across various code branches.</p> </li> <li> <p>GitHub Webhook Integration: Enabled GitHub webhooks to trigger automated builds and deployments upon code changes.</p> </li> </ul> <p> </p>"},{"location":"DevOps/#code-quality-and-security","title":"Code Quality and Security","text":"<ul> <li> <p>SonarQube Integration: Integrated SonarQube for code quality analysis and adherence to coding standards.</p> </li> <li> <p>Sonar Scanner Execution: Executed the SonarQube scanner to assess code quality and security.</p> </li> <li> <p>Custom SonarQube Rules: Defined custom rules and gates within SonarQube to enforce coding standards and security practices.</p> </li> <li> <p>SonarQube Callbacks: Set up callback rules to notify development teams of code quality issues.</p> </li> </ul> <p></p>"},{"location":"DevOps/#artifact-management","title":"Artifact Management","text":"<ul> <li> <p>JFrog Artifactory Configuration: Established JFrog Artifactory to store Docker images and other artifacts.</p> </li> <li> <p>Docker Containerization: Created Dockerfiles to containerize application components.</p> </li> </ul> <p> </p>"},{"location":"DevOps/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<ul> <li> <p>Provisioning Kubernetes Objects: Deployed Kubernetes objects such as pods, services, and deployments to facilitate application deployment.</p> </li> <li> <p>Helm Chart Deployment: Utilized Helm charts for simplified management of Kubernetes deployments and releases.</p> </li> </ul> <p></p>"},{"location":"DevOps/#monitoring-and-observability","title":"Monitoring and Observability","text":"<ul> <li>Prometheus and Grafana Setup: Configured Prometheus and Grafana using Helm charts to monitor the Kubernetes cluster and application performance.</li> </ul>"},{"location":"DevOps/#conclusion","title":"Conclusion","text":"<p>This DevOps project encompasses an array of tools and technologies to automate and streamline development, deployment, and monitoring. The integration of Jenkins, Terraform, Ansible, SonarQube, JFrog Artifactory, Kubernetes, Prometheus, and Grafana has resulted in a powerful and scalable DevOps pipeline.</p>"},{"location":"GCP/","title":"GCP","text":""},{"location":"GCP/#getting-started-with-gcp-labs","title":"Getting Started with GCP Labs","text":"<p>Welcome to our Google Cloud Platform (GCP) Labs! This guide will help you quickly get started with hands-on lab exercises in GCP.</p>"},{"location":"GCP/#prerequisites","title":"Prerequisites","text":"<p>Before diving into the labs, ensure you have the following in place:</p> <ul> <li> <p>GCP Account: You'll need a GCP account. If you don't have one, sign up at GCP Sign-Up.</p> </li> <li> <p>Google Cloud SDK: Install the Google Cloud SDK following Google Cloud SDK Installation Guide.</p> </li> <li> <p>GCP Project: Create a GCP project if you haven't already.</p> </li> </ul>"},{"location":"GCP/#lab-access","title":"Lab Access","text":"<ol> <li> <p>Lab Directory: Browse our lab directory to select a lab you'd like to work on.</p> </li> <li> <p>Instructions: Open the lab instructions for step-by-step guidance.</p> </li> <li> <p>Access GCP Console: Log in to your GCP account and access the GCP Console.</p> </li> <li> <p>Launch Lab: Follow the lab instructions to create resources, configure services, and complete the tasks.</p> </li> </ol>"},{"location":"GCP/#lab-cleanup","title":"Lab Cleanup","text":"<ul> <li>Make sure to clean up resources after completing a lab. Follow the provided instructions to avoid unnecessary costs.</li> </ul>"},{"location":"GCP/#feedback","title":"Feedback","text":"<p>We value your feedback! If you encounter issues, have questions, or want to share your insights, please contact us at abubakrm99@gmail.com.</p> <p>Let's start exploring the world of GCP through hands-on labs! Happy learning!</p>"},{"location":"Lambda/","title":"AWS Lambda Tutorial: Working with Amazon S3","text":"<p>This step-by-step tutorial will guide you through the process of creating and configure a Lambda function that resizes images added to an Amazon Simple Storage Service (Amazon S3) bucket. When you add an image file to your bucket, Amazon S3 invokes your Lambda function. The function then creates a thumbnail version of the image and outputs it to a different Amazon S3 bucket.</p>"},{"location":"Lambda/#prerequisites","title":"Prerequisites","text":"<p>Before you get started, ensure that you have the following prerequisites in place:</p> <ul> <li>AWS account</li> <li>AWS CLI</li> <li>Basic knowledge of AWS Lambda and Amazon S3</li> </ul>"},{"location":"Lambda/#steps","title":"Steps","text":""},{"location":"Lambda/#1-create-two-amazon-s3-buckets","title":"1. Create two Amazon S3 buckets","text":"<p>To create the Amazon S3 buckets (console)</p> <ol> <li> <p>Open the Buckets page of the Amazon S3 console.</p> </li> <li> <p>Choose Create bucket.</p> </li> <li> <p>Under General configuration, do the following:</p> <ul> <li> <p>For Bucket name, enter a globally unique name that meets the Amazon S3 Bucket naming rules. Bucket names can contain only lower case letters, numbers, dots (.), and hyphens (-).</p> </li> <li> <p>For AWS Region, choose the AWS Region closest to your geographical location. Later in the tutorial, you must create your Lambda function in the same AWS Region, so make a note of the region you chose.</p> </li> </ul> </li> <li> <p>Leave all other options set to their default values and choose Create bucket.</p> </li> <li> <p>Repeat steps 1 to 4 to create your destination bucket. For Bucket name, enter <code>SOURCEBUCKET-resized</code>, where <code>SOURCEBUCKET</code> is the name of the source bucket you just created.</p> </li> </ol> <p></p>"},{"location":"Lambda/#2-upload-a-test-image-to-your-source-bucket","title":"2. Upload a test image to your source bucket","text":"<p>To upload a test image to your source bucket (console)</p> <ol> <li> <p>Open the Buckets page of the Amazon S3 console.</p> </li> <li> <p>Choose Upload.</p> </li> <li> <p>Choose Add file and use the file selector to choose the object you want to upload.</p> </li> <li> <p>Choose Open, then choose Upload.</p> </li> </ol> <p></p>"},{"location":"Lambda/#3-create-a-permissions-policy","title":"3. Create a permissions policy","text":"<p>To create the policy (console)</p> <ol> <li> <p>Open the Policies page of the AWS Identity and Access Management (IAM) console.</p> </li> <li> <p>Choose Create policy.</p> </li> <li> <p>Choose the JSON tab, and then paste the following custom policy into the JSON editor.</p> </li> </ol> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"logs:PutLogEvents\",\n                \"logs:CreateLogGroup\",\n                \"logs:CreateLogStream\"\n            ],\n            \"Resource\": \"arn:aws:logs:*:*:*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetObject\"\n            ],\n            \"Resource\": \"arn:aws:s3:::*/*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:PutObject\"\n            ],\n            \"Resource\": \"arn:aws:s3:::*/*\"\n        }\n    ]\n}\n</code></pre> <ol> <li> <p>Choose Next: Tags.</p> </li> <li> <p>Choose Next: Review.</p> </li> <li> <p>Under Review policy, for Name, enter <code>LambdaS3Policy</code>.</p> </li> <li> <p>Choose Create policy.</p> </li> </ol> <p></p>"},{"location":"Lambda/#3-create-an-execution-role","title":"3. Create an execution role","text":"<p>To create an execution role and attach your permissions policy (console)</p> <ol> <li> <p>Open the Roles page of the (IAM) console.</p> </li> <li> <p>Choose Create role.</p> </li> <li> <p>For Trusted entity type, select AWS service, and for Use case, select Lambda.</p> </li> <li> <p>Choose Next.</p> </li> <li> <p>Add the permissions policy you created in the previous step by doing the following:</p> <ul> <li> <p>In the policy search box, enter <code>LambdaS3Policy</code>.</p> </li> <li> <p>In the search results, select the check box for <code>LambdaS3Policy</code>.</p> </li> <li> <p>Choose Next.</p> </li> </ul> </li> <li> <p>Under Role details, for the Role name enter <code>LambdaS3Role</code>.</p> </li> <li> <p>Choose Create role.</p> </li> </ol> <p></p>"},{"location":"Lambda/#4-create-the-function-deployment-package","title":"4. Create the function deployment package","text":"<ol> <li>Save the example code as a file named <code>lambda_function.py</code>.</li> </ol> <pre><code>import boto3\nimport os\nimport sys\nimport uuid\nfrom urllib.parse import unquote_plus\nfrom PIL import Image\nimport PIL.Image\n\ns3_client = boto3.client('s3')\n\ndef resize_image(image_path, resized_path):\n  with Image.open(image_path) as image:\n    image.thumbnail(tuple(x / 2 for x in image.size))\n    image.save(resized_path)\n\ndef lambda_handler(event, context):\n  for record in event['Records']:\n    bucket = record['s3']['bucket']['name']\n    key = unquote_plus(record['s3']['object']['key'])\n    tmpkey = key.replace('/', '')\n    download_path = '/tmp/{}{}'.format(uuid.uuid4(), tmpkey)\n    upload_path = '/tmp/resized-{}'.format(tmpkey)\n    s3_client.download_file(bucket, key, download_path)\n    resize_image(download_path, upload_path)\n    s3_client.upload_file(upload_path, '{}-resized'.format(bucket), 'resized-{}'.format(key)) \n</code></pre> <ol> <li>In the same directory in which you created your <code>lambda_function.py file</code>, create a new directory named <code>package</code> and install the Pillow (PIL) library and the AWS SDK for Python (Boto3). Although the Lambda Python runtime includes a version of the Boto3 SDK, we recommend that you add all of your function's dependencies to your deployment package, even if they are included in the runtime. For more information, see Runtime dependencies in Python.</li> </ol> <pre><code>mkdir package\npip install \\\n--platform manylinux2014_x86_64 \\\n--target=package \\\n--implementation cp \\\n--python-version 3.9 \\\n--only-binary=:all: --upgrade \\\npillow boto3 \n</code></pre> <ol> <li>Create a .zip file containing your application code and the Pillow and Boto3 libraries. In Linux or MacOS, run the following commands from your command line interface.</li> </ol> <pre><code>cd package\nzip -r ../lambda_function.zip .\ncd ..\nzip lambda_function.zip lambda_function.py\n</code></pre> <p>In Windows, use your preferred zip tool to create the lambda_function.zip file. Make sure that your lambda_function.py file and the folders containing your dependencies are all at the root of the .zip file.</p> <p></p>"},{"location":"Lambda/#5-create-the-lambda-function","title":"5. Create the Lambda function","text":"<p>To create the function (console)</p> <p>To create your Lambda function using the console, you first create a basic function containing some \u2018Hello world\u2019 code. You then replace this code with your own function code by uploading the.zip or JAR file you created in the previous step.</p> <ol> <li> <p>Open the Functions page of the Lambda console.</p> </li> <li> <p>Make sure you're working in the same AWS Region you created your Amazon S3 bucket in. You can change your region using the drop-down list at the top of the screen.</p> </li> <li> <p>Choose Create function.</p> </li> <li> <p>Choose Author from scratch.</p> </li> <li> <p>Under Basic information, do the following:</p> <ul> <li> <p>For Function name, enter <code>CreateThumbnail</code>.</p> </li> <li> <p>For Runtime choose  Python 3.9.</p> </li> <li> <p>For Architecture, choose x86_64.</p> </li> </ul> </li> <li> <p>In the Change default execution role tab, do the following:</p> <ul> <li> <p>Expand the tab, then choose Use an existing role.</p> </li> <li> <p>Select the LambdaS3Role you created earlier.</p> </li> </ul> </li> <li> <p>Choose Create function.</p> </li> </ol> <p></p> <p>To upload the function code (console)</p> <ol> <li> <p>In the Code source pane, choose Upload from.</p> </li> <li> <p>For the Python and Node.js runtimes, choose .zip file. For the Java runtime, choose .zip or .jar file.</p> </li> <li> <p>Choose Upload.</p> </li> <li> <p>In the file selector, select your .zip or JAR file and choose Open.</p> </li> <li> <p>Choose Save.</p> </li> <li> <p>next add a layer from this link (pick the correct csv for your Region): https://github.com/keithrozario/Klayers/tree/master/deployments/python3.9</p> </li> <li>select the corresponding arn for the pillow module:    </li> </ol>"},{"location":"Lambda/#6-configure-amazon-s3-to-invoke-the-function","title":"6. Configure Amazon S3 to invoke the function","text":"<p>To configure the Amazon S3 trigger (console)</p> <ol> <li> <p>Open the Functions page of the Lambda console and choose your function (<code>CreateThumbnail</code>).</p> </li> <li> <p>Choose Add trigger.</p> </li> <li> <p>Select S3.</p> </li> <li> <p>Under Bucket, select your source bucket.</p> </li> <li> <p>Under Event types, select All object create events.</p> </li> <li> <p>Under Recursive invocation, select the check box to acknowledge that using the same Amazon S3 bucket for input and output is not recommended. You can learn more about recursive invocation patterns in Lambda by reading Recursive patterns that cause run-away Lambda functions in Serverless Land.</p> </li> <li> <p>Choose Add.</p> </li> </ol> <p></p>"},{"location":"Lambda/#7-test-your-lambda-function-with-a-dummy-event","title":"7. Test your Lambda function with a dummy event","text":"<p>To test your Lambda function with a dummy event (console)</p> <ol> <li> <p>Open the Functions page of the Lambda console and choose your function (<code>CreateThumbnail</code>).</p> </li> <li> <p>Choose the Test tab.</p> </li> <li> <p>To create your test event, in the Test event pane, do the following:</p> <ul> <li> <p>Under Test event action, select Create new event.</p> </li> <li> <p>For Event name, enter <code>myTestEvent</code>.</p> </li> <li> <p>For Template, select S3 Put.</p> </li> <li> <p>Replace the values for the following parameters with your own values.</p> <ul> <li> <p>For <code>awsRegion</code>, replace <code>us-east-1</code> with the AWS Region you created your Amazon S3 buckets in.</p> </li> <li> <p>For <code>name</code>, replace <code>example-bucket</code> with the name of your own Amazon S3 source bucket.</p> </li> <li> <p>For <code>key</code>, replace <code>test%2Fkey</code> with the filename of the test object you uploaded to your source bucket in the step Upload a test image to your source bucket.</p> </li> </ul> </li> </ul> </li> </ol> <pre><code>{\n  \"Records\": [\n    {\n      \"eventVersion\": \"2.0\",\n      \"eventSource\": \"aws:s3\",\n      \"awsRegion\": \"us-east-1\",\n      \"eventTime\": \"1970-01-01T00:00:00.000Z\",\n      \"eventName\": \"ObjectCreated:Put\",\n      \"userIdentity\": {\n        \"principalId\": \"EXAMPLE\"\n      },\n      \"requestParameters\": {\n        \"sourceIPAddress\": \"127.0.0.1\"\n      },\n      \"responseElements\": {\n        \"x-amz-request-id\": \"EXAMPLE123456789\",\n        \"x-amz-id-2\": \"EXAMPLE123/5678abcdefghijklambdaisawesome/mnopqrstuvwxyzABCDEFGH\"\n      },\n      \"s3\": {\n        \"s3SchemaVersion\": \"1.0\",\n        \"configurationId\": \"testConfigRule\",\n        \"bucket\": {\n          \"name\": \"example-bucket\",\n          \"ownerIdentity\": {\n            \"principalId\": \"EXAMPLE\"\n          },\n          \"arn\": \"arn:aws:s3:::example-bucket\"\n        },\n        \"object\": {\n          \"key\": \"test%2Fkey\",\n          \"size\": 1024,\n          \"eTag\": \"0123456789abcdef0123456789abcdef\",\n          \"sequencer\": \"0A1B2C3D4E5F678901\"\n        }\n      }\n    }\n  ]\n}\n</code></pre> <p>Choose Save.</p> <ol> <li>In the Test event pane, choose Test.</li> </ol> <p></p> <ul> <li>too ensure the function works. increase the timeout length to 15 seconds.</li> </ul> <p></p> <ol> <li> <p>To check the your function has created a resized verison of your image and stored it in your target Amazon S3 bucket, do the following:</p> <p>-Open the Buckets page of the Amazon S3 console.</p> <p>-Choose your target bucket and confirm that your resized file is listed in the Objects pane.</p> <p></p> </li> </ol> Clean up your resources <p>You can now delete the resources that you created for this tutorial, unless you want to retain them. By deleting AWS resources that you're no longer using, you prevent    unnecessary charges to your AWS account.</p> <p>To delete the Lambda function</p> <ol> <li> <p>Open the Functions page of the Lambda console.</p> </li> <li> <p>Select the function that you created.</p> </li> <li> <p>Choose Actions, Delete.</p> </li> <li> <p>Type <code>delete</code> in the text input field and choose Delete.</p> </li> </ol> <p>To delete the policy that you created</p> <ol> <li> <p>Open the Policies page of the IAM console.</p> </li> <li> <p>Select the policy that you created (AWSLambdaS3Policy).</p> </li> <li> <p>Choose Policy actions, Delete.</p> </li> <li> <p>Choose Delete.</p> </li> </ol> <p>To delete the execution role</p> <ol> <li> <p>Open the Roles page of the IAM console.</p> </li> <li> <p>Select the execution role that you created.</p> </li> <li> <p>Choose Delete.</p> </li> <li> <p>Enter the name of the role in the text input field and choose Delete.</p> </li> </ol> <p>To delete the S3 bucket</p> <ol> <li> <p>Open the Amazon S3 console.</p> </li> <li> <p>Select the bucket you created.</p> </li> <li> <p>Choose Delete.</p> </li> <li> <p>Enter the name of the bucket in the text input field.</p> </li> <li> <p>Choose Delete bucket.</p> </li> </ol>"},{"location":"Lambda/#conclusion","title":"Conclusion","text":"<p>Congratulations on creating a resized image with Amazon S3 and Lambda!</p>"},{"location":"azurelb/","title":"Deploying Website with Azure Load Balancer","text":""},{"location":"azurelb/#step-1-create-a-resource-group","title":"Step 1: Create a Resource Group","text":"<ol> <li>Sign in to the Azure Portal https://portal.azure.com.</li> <li>Click on the \"Create a resource\" button (green plus sign) in the upper-left corner.</li> <li>Search for \"Resource group\" and select it.</li> <li>Click the \"Create\" button.</li> <li>Fill in the details for the resource group:</li> <li>Subscription: Choose your Azure subscription.</li> <li>Resource group: Enter a unique name for your resource group.</li> <li>Region: Select a region for your resource group.</li> <li>Click the \"Review + create\" button and then \"Create\" to create the resource group.</li> </ol> Resource Group"},{"location":"azurelb/#step-2-create-a-network-security-group-nsg-with-inbound-rules","title":"Step 2: Create a Network Security Group (NSG) with Inbound Rules","text":"<ol> <li>In the Azure Portal, search for \"Network security group\" and select it.</li> <li>Click the \"Create\" button.</li> <li>Fill in the details for the NSG:</li> <li>Name: Enter a unique name for your NSG.</li> <li>Resource group: Choose the resource group created in Step 1.</li> <li>Region: Select the same region as your resource group.</li> <li> <p>Click the \"Review + create\" button and then \"Create\" to create the NSG.</p> </li> <li> <p>After creating the NSG, select it and navigate to the \"Inbound security rules\" section.</p> </li> <li> <p>Add the following inbound rules:</p> </li> <li> <p>Rule 1: SSH (Port 22 Inbound)</p> <ul> <li>Name: SSH</li> <li>Priority: Choose a priority value (e.g., 100)</li> <li>Source: Any</li> <li>Service: SSH</li> <li>Action: Allow</li> </ul> </li> <li> <p>Rule 2: HTTP (Port 80 Inbound)</p> <ul> <li>Name: HTTP</li> <li>Priority: Choose a priority value (e.g., 200)</li> <li>Source: Any</li> <li>Service: HTTP</li> <li>Action: Allow</li> </ul> </li> <li> <p>Rule 3: ICMP Deny (Block All ICMP Inbound)</p> <ul> <li>Name: ICMP Deny</li> <li>Priority: Set the priority to 101</li> <li>Source: Any</li> <li>Service: ICMP</li> <li>Action: Deny</li> </ul> </li> <li> <p>Save the changes to the NSG.</p> </li> </ol> Network Security Group NSGSSHHTTPICMP <p></p> <p></p> <p></p> <p></p>"},{"location":"azurelb/#step-3-create-a-virtual-network-vnet","title":"Step 3: Create a Virtual Network (VNet)","text":"<ol> <li>In the Azure Portal, search for \"Virtual network\" and select it.</li> <li>Click the \"Create\" button.</li> <li>Fill in the details for the VNet:</li> <li>Name: Enter a unique name for your VNet.</li> <li>Resource group: Choose the resource group created in Step 1.</li> <li>Region: Select the same region as your resource group.</li> <li>Configure the address space and subnets for your VNet.</li> <li>Click the \"Review + create\" button and then \"Create\" to create the VNet.</li> </ol> Virutal Network VNetSubnetASubnetBIP Addresses"},{"location":"azurelb/#step-4-create-a-load-balancer","title":"Step 4: Create a Load Balancer","text":"<ol> <li>In the Azure Portal, search for \"Load balancer\" and select it.</li> <li>Click the \"Create\" button.</li> <li>Fill in the details for the load balancer:</li> <li>Name: Enter a unique name for your load balancer.</li> <li>Resource group: Choose the resource group created in Step 1.</li> <li>Region: Select the same region as your resource group.</li> <li>Choose the \"Internet-facing\" or \"Internal\" load balancer, depending on your requirements.</li> <li>Configure the front-end IP configuration, back-end pools, and health probes as needed.</li> <li>Click the \"Review + create\" button and then \"Create\" to create the load balancer.</li> </ol> Load Balancer BasicsFrontend IP configurationPublic IP Address (frontend IP configuration)Backend PoolLoad Balancing RuleInbound NAT Rule"},{"location":"azurelb/#step-5-create-a-virtual-machine-scale-set-vmss","title":"Step 5: Create a Virtual Machine Scale Set (VMSS)","text":"<ol> <li>In the Azure Portal, search for \"Virtual machine scale set\" and select it.</li> <li>Click the \"Create\" button.</li> <li>Fill in the details for the VMSS:</li> <li>Basics:<ul> <li>Subscription: Choose your Azure subscription.</li> <li>Resource group: Choose the resource group created in Step 1.</li> <li>Region: Select the same region as your resource group.</li> <li>Name: Enter a unique name for your VMSS.</li> </ul> </li> <li>Image:<ul> <li>Choose a base image for your virtual machines.</li> </ul> </li> <li>Disks<ul> <li>change the OS disk type to Standard SSD</li> </ul> </li> <li>Networking:<ul> <li>Virtual network: Select the VNet created in Step 3.</li> <li>Subnet: Choose a subnet within the VNet.</li> <li>Public IP address: Depending on your configuration, choose to have a public IP or not.</li> <li>Load balancer: Select the load balancer created in Step 4.</li> </ul> </li> <li>Scaling:<ul> <li>Configure the scaling options based on your requirements.</li> </ul> </li> <li>Advanced:<ul> <li>select Enable User Data and input the following command.</li> </ul> </li> </ol> <pre><code>#!/bin/bash\n\n# Update system and install Apache2 and jq\napt-get update -y\napt-get install -y apache2 jq\n\n# Ensure Apache2 is running and enabled on boot\nsystemctl start apache2\nsystemctl enable apache2\n\n# Fetch Azure VM metadata\nMETADATA=$(curl -H Metadata:true -s \"http://169.254.169.254/metadata/instance?api-version=2021-01-01\")\n\n# Log metadata for debugging purposes\necho \"$METADATA\" &gt; /tmp/metadata.json\n\n# Extract data from the fetched metadata\nlocal_ipv4=$(echo \"$METADATA\" | jq -r '.network.interface[0].ipv4.ipAddress[0].privateIpAddress')\naz=$(echo \"$METADATA\" | jq -r '.compute.location')\nvm_id=$(echo \"$METADATA\" | jq -r '.compute.vmId')\n\n# Generate an HTML file with the extracted data\ncat &lt;&lt;EOF &gt; /var/www/html/index.html\n&lt;!doctype html&gt;\n&lt;html lang=\"en\" class=\"h-100\"&gt;\n&lt;head&gt;\n&lt;title&gt;Details for Azure VM&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;div&gt;\n&lt;h1&gt;Azure Instance Details&lt;/h1&gt;\n&lt;h1&gt;Samurai Katana&lt;/h1&gt;\n\n&lt;p&gt;&lt;b&gt;Instance Name:&lt;/b&gt; $(hostname -f)&lt;/p&gt;\n&lt;p&gt;&lt;b&gt;Instance Private IP Address:&lt;/b&gt; ${local_ipv4}&lt;/p&gt;\n&lt;p&gt;&lt;b&gt;Availability Zone:&lt;/b&gt; ${az}&lt;/p&gt;\n&lt;p&gt;&lt;b&gt;Virtual Machine ID:&lt;/b&gt; ${vm_id}&lt;/p&gt;\n&lt;/div&gt;\n&lt;/body&gt;\n&lt;/html&gt;\nEOF\n\n# Remove the temporary file\nrm /tmp/metadata.json\n</code></pre> VMSS Basics pt. 1Basics pt. 2DisksNetwork InterfaceNetoworkingScalingHealthUser Data (advanced) <ol> <li>Click the \"Review + create\" button and then \"Create\" to create the VMSS.<ul> <li>copy the public IP address of the VMSS and add http:// to the beginning and paste it into a new tab. your new website should be live.</li> </ul> </li> </ol>"},{"location":"azurelb/#congratulations","title":"Congratulations! \ud83c\udf89","text":"<p>You've successfully completed the lab!</p> <p></p>"}]}